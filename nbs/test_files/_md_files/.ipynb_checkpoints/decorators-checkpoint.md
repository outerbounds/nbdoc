# Decorators

<!--- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file.-->


<DocSection type="decorator" name="batch" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/batch/batch_decorator.py#L30">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="Step decorator to specify that this step should execute on AWS Batch." extended_summary="This decorator indicates that your step should execute on AWS Batch. Note\nthat you can apply this decorator automatically to all steps using the\n```--with batch``` argument when calling run/resume. Step level decorators\nwithin the code are overrides and will force a step to execute on AWS Batch\nregardless of the ```--with``` specification.\n\nTo use, annotate your step as follows:\n```\n@batch\n@step\ndef my_step(self):\n    ...\n```\nParameters\n----------\ncpu : int\n    Number of CPUs required for this step. Defaults to 1. If @resources is\n    also present, the maximum value from all decorators is used\ngpu : int\n    Number of GPUs required for this step. Defaults to 0. If @resources is\n    also present, the maximum value from all decorators is used\nmemory : int\n    Memory size (in MB) required for this step. Defaults to 4096. If\n    @resources is also present, the maximum value from all decorators is\n    used\nimage : string\n    Docker image to use when launching on AWS Batch. If not specified, a\n    default docker image mapping to the current version of Python is used\nqueue : string\n    AWS Batch Job Queue to submit the job to. Defaults to the one\n    specified by the environment variable METAFLOW_BATCH_JOB_QUEUE\niam_role : string\n    AWS IAM role that AWS Batch container uses to access AWS cloud resources\n    (Amazon S3, Amazon DynamoDb, etc). Defaults to the one specified by the\n    environment variable METAFLOW_ECS_S3_ACCESS_IAM_ROLE\nexecution_role : string\n    AWS IAM role that AWS Batch can use to trigger AWS Fargate tasks.\n    Defaults to the one determined by the environment variable\n    METAFLOW_ECS_FARGATE_EXECUTION_ROLE https://docs.aws.amazon.com/batch/latest/userguide/execution-IAM-role.html\nshared_memory : int\n    The value for the size (in MiB) of the /dev/shm volume for this step.\n    This parameter maps to the --shm-size option to docker run.\nmax_swap : int\n    The total amount of swap memory (in MiB) a container can use for this\n    step. This parameter is translated to the --memory-swap option to\n    docker run where the value is the sum of the container memory plus the\n    max_swap value.\nswappiness : int\n    This allows you to tune memory swappiness behavior for this step.\n    A swappiness value of 0 causes swapping not to happen unless absolutely\n    necessary. A swappiness value of 100 causes pages to be swapped very\n    aggressively. Accepted values are whole numbers between 0 and 100." />
<ParamSection name="Attributes">
	<Parameter name="package_sha" />
	<Parameter name="package_url" />
	<Parameter name="run_time_limit" />
</ParamSection>
</DocSection>



<DocSection type="decorator" name="card" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_decorator.py#L24">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>


</DocSection>



<DocSection type="decorator" name="catch" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/catch_decorator.py#L22">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="Step decorator to specify error handling for your step." extended_summary="This decorator indicates that exceptions in the step should be caught and not fail the entire\nflow.\n\nThis can be used in conjunction with the @retry decorator. In that case, catch will only\nactivate if all retries fail and will catch the last exception thrown by the last retry.\n\nTo use, annotate your step as follows:\n```\n@catch(var='foo')\n@step\ndef myStep(self):\n    ...\n```" />
<ParamSection name="Parameters">
	<Parameter name="var" type="string" desc="Name of the artifact in which to store the caught exception. If not specified,\nthe exception is not stored" />
	<Parameter name="print_exception" type="bool" desc="Determines whether or not the exception is printed to stdout when caught. Defaults\nto True" />
</ParamSection>
</DocSection>



<DocSection type="decorator" name="conda" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/conda/conda_step_decorator.py#L38">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="Conda decorator that sets the Conda environment for your step" extended_summary="To use, add this decorator to your step:\n```\n@conda\n@step\ndef MyStep(self):\n    ...\n```\n\nInformation in this decorator will override any eventual @conda_base flow level decorator.\nParameters\n----------\nlibraries : Dict\n    Libraries to use for this flow. The key is the name of the package and the value\n    is the version to use. Defaults to {}\npython : string\n    Version of Python to use (for example: '3.7.4'). Defaults to None\n    (will use the current python version)\ndisabled : bool\n    If set to True, disables Conda. Defaults to False" />
<ParamSection name="Attributes">
	<Parameter name="conda" />
	<Parameter name="environments" />
</ParamSection>
</DocSection>



<DocSection type="decorator" name="kubernetes" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/eks/kubernetes_decorator.py#L24">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="TODO (savin): Update this docstring.\nStep decorator to specify that this step should execute on Kubernetes." extended_summary="This decorator indicates that your step should execute on Kubernetes. Note\nthat you can apply this decorator automatically to all steps using the\n```--with kubernetes``` argument when calling run/resume. Step level\ndecorators within the code are overrides and will force a step to execute\non Kubernetes regardless of the ```--with``` specification.\n\nTo use, annotate your step as follows:\n```\n@kubernetes\n@step\ndef my_step(self):\n    ...\n```\nParameters\n----------\ncpu : int\n    Number of CPUs required for this step. Defaults to 1. If @resources is\n    also present, the maximum value from all decorators is used\ngpu : int\n    Number of GPUs required for this step. Defaults to 0. If @resources is\n    also present, the maximum value from all decorators is used\nmemory : int\n    Memory size (in MB) required for this step. Defaults to 4096. If\n    @resources is also present, the maximum value from all decorators is\n    used\nimage : string\n    Docker image to use when launching on Kubernetes. If not specified, a\n    default docker image mapping to the current version of Python is used\nshared_memory : int\n    The value for the size (in MiB) of the /dev/shm volume for this step.\n    This parameter maps to the --shm-size option to docker run." />
<ParamSection name="Attributes">
	<Parameter name="package_sha" />
	<Parameter name="package_url" />
	<Parameter name="run_time_limit" />
</ParamSection>
</DocSection>



<DocSection type="decorator" name="parallel" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/parallel_decorator.py#L8">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>


</DocSection>



<DocSection type="decorator" name="project" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/project_decorator.py#L15">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>


</DocSection>



<DocSection type="decorator" name="resources" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/resources_decorator.py#L4">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="Step decorator to specify the resources needed when executing this step." extended_summary="This decorator passes this information along to container orchestrator\n(AWS Batch, Kubernetes, etc.) when requesting resources to execute this\nstep.\n\nThis decorator is ignored if the execution of the step happens locally.\n\nTo use, annotate your step as follows:\n```\n@resources(cpu=32)\n@step\ndef my_step(self):\n    ...\n```\nParameters\n----------\ncpu : int\n    Number of CPUs required for this step. Defaults to 1\ngpu : int\n    Number of GPUs required for this step. Defaults to 0\nmemory : int\n    Memory size (in MB) required for this step. Defaults to 4096\nshared_memory : int\n    The value for the size (in MiB) of the /dev/shm volume for this step.\n    This parameter maps to the --shm-size option to docker run ." />

</DocSection>



<DocSection type="decorator" name="@step" module="metaflow" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/metaflow/decorators.py#L493">
<SigArgSection>
<SigArg name="..." />
</SigArgSection>
<Description summary="The step decorator. Makes a method a step in the workflow." />

</DocSection>